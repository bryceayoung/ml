{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98c21f6-2759-47be-be6e-4a04dc0b6524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##----LOAD DATA ---------------------------------------------------------------\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Define and scale features\n",
    "X = train[['f1','f2','f3','f4','f5']].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "\n",
    "# Define training target\n",
    "y = train[['target']].copy()\n",
    "\n",
    "# Define test features\n",
    "X_test = test[['f1','f2','f3','f4','f5']].copy()\n",
    "Xs_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3207de1-9565-4c2d-9fdb-9470d02248fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE Scores: [1.5931141  2.30062041 3.09987972 1.46457834 2.78350167]\n",
      "Mean RMSE: 2.2483388468015915\n"
     ]
    }
   ],
   "source": [
    "##---- FIT A GLM USING 3 FEATURES AS 3RD ORDER POLYNOMIALS ----------------------------\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create a pipeline with PolynomialFeatures and LinearRegression\n",
    "degree = 3  # Degree of the polynomial features\n",
    "glm1 = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "\n",
    "# Fit the model\n",
    "glm1.fit(Xs[:, [2, 3, 4]], y)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(glm1, Xs[:, [2, 3, 4]], y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert the scores to positive since cross_val_score returns neg_mean_squared_error\n",
    "cv_rmse_scores = (-cv_scores)**0.5\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(f'Cross-Validation RMSE Scores: {cv_rmse_scores}')\n",
    "print(f'Mean RMSE: {cv_rmse_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e71fba0c-a633-469b-a0c5-7392cd741328",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##---- GENERATE PREDICTIONS AND EXPORT -------------------------------------------------------\n",
    "# Predict\n",
    "y_pred_glm1 = glm1.predict(Xs_test[:, [2, 3, 4]])\n",
    "\n",
    "# Make a Dataframe\n",
    "glm1_preds = test[['id']].copy()\n",
    "glm1_preds['target'] = y_pred_glm1\n",
    "\n",
    "# Export\n",
    "glm1_preds.to_csv('glm1_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c963e58a-0343-499f-96e4-b62ada162fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best Hyperparameters: {'polynomialfeatures__degree': 3, 'ridge__alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "##---- USE GRID SEARCH TO OPTIMIZE GLM ------------------------------------\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Create a pipeline with PolynomialFeatures and Ridge regression\n",
    "glm_model = make_pipeline(PolynomialFeatures(), Ridge())\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'polynomialfeatures__degree': [2, 3, 4],\n",
    "    'ridge__alpha': [0.1, 1, 10]  # Adjust the range as needed\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=glm_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(Xs, y)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ca8bd08-5052-4c3b-a120-a5221fef38d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE Scores: [1.0619385  1.29727749 1.14691452 1.02052444 1.18961838]\n",
      "Mean RMSE: 1.1432546646089168\n"
     ]
    }
   ],
   "source": [
    "##---- CREATE SECOND GLM WITH ABOVE HYPERPARAMETERS --------------------------\n",
    "\n",
    "# Create a pipeline with PolynomialFeatures and Ridge regression using the best hyperparameters\n",
    "degree = 3\n",
    "alpha = 1\n",
    "\n",
    "glm2 = make_pipeline(\n",
    "    PolynomialFeatures(degree=degree),\n",
    "    Ridge(alpha=alpha)\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "glm2.fit(Xs, y)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(glm2, Xs, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert the scores to positive since cross_val_score returns neg_mean_squared_error\n",
    "cv_rmse_scores = (-cv_scores)**0.5\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(f'Cross-Validation RMSE Scores: {cv_rmse_scores}')\n",
    "print(f'Mean RMSE: {cv_rmse_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0114f0b0-44af-494b-96df-c2764e1b0e08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##---- GENERATE PREDICTIONS AND EXPORT -------------------------------------------------------\n",
    "# Predict\n",
    "y_pred_glm2 = glm2.predict(Xs_test)\n",
    "\n",
    "# Make a Dataframe\n",
    "glm2_preds = test[['id']].copy()\n",
    "glm2_preds['target'] = y_pred_glm2\n",
    "\n",
    "# Export\n",
    "glm2_preds.to_csv('glm2_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac9c4ad6-a2cc-4fb4-b67a-cdf3fa270b59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE Scores: [1.06528062 1.28682087 1.15159552 1.01500964 1.19315366]\n",
      "Mean RMSE: 1.1423720621055555\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with PolynomialFeatures and Ridge regression using the best hyperparameters\n",
    "degree = 3\n",
    "alpha = 2\n",
    "\n",
    "glm3 = make_pipeline(\n",
    "    PolynomialFeatures(degree=degree),\n",
    "    Ridge(alpha=alpha)\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "glm3.fit(Xs, y)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(glm3, Xs, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert the scores to positive since cross_val_score returns neg_mean_squared_error\n",
    "cv_rmse_scores = (-cv_scores)**0.5\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(f'Cross-Validation RMSE Scores: {cv_rmse_scores}')\n",
    "print(f'Mean RMSE: {cv_rmse_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "464d1b7b-391b-4453-8b29-0b43656ce9df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_glm3 = glm3.predict(Xs_test)\n",
    "\n",
    "# Make a Dataframe\n",
    "glm3_preds = test[['id']].copy()\n",
    "glm3_preds['target'] = y_pred_glm3\n",
    "\n",
    "# Export\n",
    "glm3_preds.to_csv('glm3_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19beb0ec-46d0-4af4-8792-c1008549ed2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\by197116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for SVR: {'polynomialfeatures__degree': 3, 'svr__C': 1, 'svr__epsilon': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\by197116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\by197116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\by197116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\by197116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVR Cross-Validation RMSE Scores: [1.06724701 1.38555173 1.17207283 0.96561582 1.20573637]\n",
      "Mean RMSE for SVR: 1.1592447487855062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\by197116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "##---- SUPPORT VECTOR REGRESSOR --------------------------------------------------------\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Create a pipeline with PolynomialFeatures and SVR\n",
    "degree = 3\n",
    "C = 1  # Regularization parameter\n",
    "epsilon = 0.1  # Epsilon in the SVR model\n",
    "\n",
    "svm_model = make_pipeline(\n",
    "    PolynomialFeatures(degree=degree),\n",
    "    SVR(kernel='linear', C=C, epsilon=epsilon)\n",
    ")\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid_svr = {\n",
    "    'polynomialfeatures__degree': [2, 3, 4],\n",
    "    'svr__C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'svr__epsilon': [0.01, 0.1, 0.2]  # Epsilon in the SVR model\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_svr = GridSearchCV(estimator=svm_model, param_grid=param_grid_svr, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_svr.fit(Xs, y)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters for SVR:\", grid_search_svr.best_params_)\n",
    "\n",
    "# Use the best model from the grid search\n",
    "best_svr_model = grid_search_svr.best_estimator_\n",
    "\n",
    "# Perform cross-validation with SVR\n",
    "cv_scores_svr = cross_val_score(best_svr_model, Xs, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert the scores to positive since cross_val_score returns neg_mean_squared_error\n",
    "cv_rmse_scores_svr = (-cv_scores_svr)**0.5\n",
    "\n",
    "# Print the cross-validation results for SVR\n",
    "print(f'\\nSVR Cross-Validation RMSE Scores: {cv_rmse_scores_svr}')\n",
    "print(f'Mean RMSE for SVR: {cv_rmse_scores_svr.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8f18de6-d0b3-4573-9f7a-3a3bb1098508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svr1 = best_svr_model\n",
    "# Predict\n",
    "y_pred_svr1 = svr1.predict(Xs_test)\n",
    "\n",
    "# Make a Dataframe\n",
    "svr1_preds = test[['id']].copy()\n",
    "svr1_preds['target'] = y_pred_glm3\n",
    "\n",
    "# Export\n",
    "svr1_preds.to_csv('svr1_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561ed517-394c-4f99-98b2-6d7f85e5343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "##---- ATTEMPT TO IMPROVE VARIABLE SELECTION --------------------------------------------------\n",
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42e5c3a6-22fb-43f8-b909-febe3ec8bb8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##----LOAD DATA ---------------------------------------------------------------\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Define and scale features\n",
    "X = train[['f1','f3','f4','f5','f7']].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "\n",
    "# Define training target\n",
    "y = train[['target']].copy()\n",
    "\n",
    "# Define test features\n",
    "X_test = test[['f1','f3','f4','f5','f7']].copy()\n",
    "Xs_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a78d99a9-b1c7-4433-a530-eaac5ef2b3cd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\by197116\\AppData\\Local\\Temp\\ipykernel_14856\\797944260.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X1s, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.04172323009911918\n",
      "f2: 0.033333829738277254\n",
      "f5: 0.5398523939710622\n",
      "f6: 0.03922467963110824\n",
      "f7: 0.024560297667447644\n",
      "f11: 0.036256485103906506\n",
      "f12: 0.04178144936887593\n",
      "f13: 0.02661686919470644\n",
      "f14: 0.028466535116066876\n",
      "f15: 0.03345437618423797\n",
      "f16: 0.03865936985643073\n",
      "f17: 0.029500123816292956\n",
      "f18: 0.021437261585121214\n",
      "f19: 0.022972256861351032\n",
      "f20: 0.04216084180599592\n"
     ]
    }
   ],
   "source": [
    "##---- Look at feature importance with random forest --------------------\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "\n",
    "# Define and scale subset\n",
    "X1 = train[['f1','f2','f6','f7','f11','f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20']].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X1s = scaler.fit_transform(X1)\n",
    "\n",
    "# Initialize\n",
    "rf = rfr(n_estimators=200, \n",
    "          random_state=42)\n",
    "\n",
    "# Fit\n",
    "rf.fit(X1s, y)\n",
    "\n",
    "# Print feature importances\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Store features in a variable 'feature_names' and print importance\n",
    "feature_names = X1.columns\n",
    "\n",
    "for feature_name, importance in zip(feature_names, feature_importances):\n",
    "    print(f'{feature_name}: {importance}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b063cde7-a43b-4b79-b8d5-5312341684ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best Hyperparameters: {'polynomialfeatures__degree': 3, 'ridge__alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "##---- USE GRID SEARCH TO OPTIMIZE GLM ------------------------------------\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a pipeline with PolynomialFeatures and Ridge regression\n",
    "glm_model = make_pipeline(PolynomialFeatures(), Ridge())\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'polynomialfeatures__degree': [2, 3, 4],\n",
    "    'ridge__alpha': [0.1, 1, 10]  # Adjust the range as needed\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=glm_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(Xs, y)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fd234ce-9068-4285-8709-4e6545da89ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE Scores: [1.05952392 1.29289187 1.11381574 1.02088853 1.17030878]\n",
      "Mean RMSE: 1.1314857671597869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create a pipeline with PolynomialFeatures and Ridge regression using the best hyperparameters\n",
    "degree = 3\n",
    "alpha = 1\n",
    "\n",
    "glm4 = make_pipeline(\n",
    "    PolynomialFeatures(degree=degree),\n",
    "    Ridge(alpha=alpha)\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "glm4.fit(Xs, y)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(glm4, Xs, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert the scores to positive since cross_val_score returns neg_mean_squared_error\n",
    "cv_rmse_scores = (-cv_scores)**0.5\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(f'Cross-Validation RMSE Scores: {cv_rmse_scores}')\n",
    "print(f'Mean RMSE: {cv_rmse_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63c96675-10d2-4769-9a79-5a0d635f201c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_glm4 = glm4.predict(Xs_test)\n",
    "\n",
    "# Make a Dataframe\n",
    "glm4_preds = test[['id']].copy()\n",
    "glm4_preds['target'] = y_pred_glm4\n",
    "\n",
    "# Export\n",
    "glm4_preds.to_csv('glm4_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb710ede-3ef2-40a5-a2a4-6dc4a3aba992",
   "metadata": {},
   "outputs": [],
   "source": [
    "##---- VISUALIZING PREDICTORS --------------------------------------------\n",
    "\n",
    "# Set up a 5x3 grid\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 5))\n",
    "\n",
    "# Flatten the 2D array of subplots for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Variables 'f1' to 'f5'\n",
    "variables = ['f1', 'f2', 'f3', 'f4', 'f5']\n",
    "\n",
    "# Response variable\n",
    "target_variable = 'target'\n",
    "\n",
    "# Create scatter plots for each variable against 'target' in the grid\n",
    "for i, variable in enumerate(variables):\n",
    "    sns.scatterplot(x=train[variable], y=train[target_variable], ax=axes[i])\n",
    "    axes[i].set_title(f'Scatter Plot for {variable} vs. {target_variable}')\n",
    "    axes[i].set_xlabel(variable)\n",
    "    axes[i].set_ylabel(target_variable)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
